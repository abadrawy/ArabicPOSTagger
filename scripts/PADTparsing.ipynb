{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentences=[]\n",
    "paths=['PADT_LDC/data/ALH/syntax/','PADT_LDC/data/UMH/syntax/','PADT_LDC/data/XIN/syntax/','PADT_LDC/data/XIA/syntax/','PADT_LDC/data/ANN/syntax/','PADT_LDC/data/AFP/syntax/']\n",
    "sentennce =[]\n",
    "sent_no=0\n",
    "next_index=0\n",
    "saved_word=\"\"\n",
    "saved_tag=\"\"\n",
    "suffix=['هن','ها','هما','ه','ما','كم','ني','هم','نا','ك','ا','ي']\n",
    "prefix=['ال','ما','']\n",
    "pron=['ني', 'كيف', 'ه', 'هن', 'هذان', 'من', 'هي', 'نحن', 'ا', 'ذا', 'ماهو', 'أين', 'ها', 'أولئك', 'أية', 'هٰؤلاء', 'ذاك', 'الذين', 'نا', 'هما', 'أنا', 'هذه', 'هم', 'للاتي', 'التي', 'أيا', 'ذلك', 'هو', 'هٰذه', 'ذوي', 'الذي', 'هٰذا', 'متى', 'هذا', 'أي', 'اللذان', 'هاتان', 'هٰذين', 'اللواتي', 'اللتين', 'هؤلاء', 'كم', 'ك', 'ذي', 'ما', 'ذٰلك', 'ي', 'تلك']\n",
    "adp=['تجاه', 'حوالى', 'فور', 'ب', 'مع', 'إزاء', 'وراء', 'سوا', 'لدي', 'من', 'داخل', 'أما', 'رغم', 'بشأن', 'وفق', 'حوالي', 'بلا', 'خارج', 'نحو', 'عبر', 'بإزاء', 'إثر', 'تحت', 'عوض', 'قيد', 'حيال', 'بسبب', 'سوى', 'ضد', 'جراء', 'عقب', 'مثل', 'خلف', 'لدى', 'بعيد', 'بدون', 'قبل', 'أمام', 'خلال', 'طوال', 'ضمن', 'منمن', 'علي', 'دون', 'ل', 'حين', 'وسط', 'بين', 'إلى', 'عدا', 'قرب', 'شرق', 'فوق', 'قبالة', 'في', 'ك', 'عند', 'إلي', 'بعد', 'على', 'منذ', 'حتى', 'حول', 'عن', 'أثناء']\n",
    "conj=['حيث', 'مما', 'أن', 'كأنما', 'مهما', 'لكي', 'لكن', 'هكذا', 'فيما', 'طال', 'مالم', 'لعل', 'عندما', 'لأن', 'حتى', 'حينما', 'ولو', 'ف', 'لذٰلك', 'إنما', 'و', 'لٰكن', 'إذا', 'لو', 'إن', 'لولا', 'ألا', 'أنلا', 'بل', 'كذا', 'حسبما', 'مثل', 'إذ', 'لما', 'طالما', 'كي', 'أو', 'متى', 'كما', 'حسب', 'أي', 'حين', 'بينما', 'أينما', 'أم', 'إما', 'عل', 'كل', 'كلما', 'عند', 'إلا', 'منذ', 'لذلك', 'مثلما', 'لذا', 'ل']\n",
    "prt=['إيا', 'أن', 'ماذا', 'فور', 'أ', 'ناهيك', 'من', 'س', 'هلا', 'لماذا', 'إن', 'هل', 'عما', 'لا', 'أيا', 'سوى', 'لقد', 'قد', 'لما', 'كلا', 'شبعا', 'لئن', 'سوف', 'أي', 'لن', 'عل', 'إلا', 'ما', 'لم', 'غير', 'ل']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deNoise(text):\n",
    "    noise = re.compile(\"\"\"  ّ    | # Tashdid\n",
    "                            َ    | # Fatha\n",
    "                            ً    | # Tanwin Fath\n",
    "                            ُ    | # Damma\n",
    "                            ٌ    | # Tanwin Damm\n",
    "                            ِ    | # Kasra\n",
    "                            ٍ    | # Tanwin Kasr\n",
    "                            ْ    | # Sukun\n",
    "                            \\u0670|\n",
    "                              ـ     # Tatwil/Kashida\n",
    "                                \"\"\", re.VERBOSE)\n",
    "    text = re.sub(noise, '', text)\n",
    "    return text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_index(sentennce):\n",
    "    sent=[]\n",
    "    for (tag,index,word) in sentennce:\n",
    "        sent.append((tag,word))\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_tag(d_tag):\n",
    "    if d_tag.startswith(\"S\"):\n",
    "         return \"PRON\"\n",
    "    elif d_tag.startswith(\"A\"):\n",
    "          return \"ADJ\"\n",
    "    elif d_tag.startswith(\"P\"):\n",
    "          return \"ADP\"\n",
    "    elif d_tag.startswith(\"D\"):\n",
    "          return \"ADV\"\n",
    "    elif d_tag.startswith(\"C\"):\n",
    "          return \"CONJ\"\n",
    "    elif d_tag.startswith(\"N\") or d_tag.startswith(\"Z\"):\n",
    "         return \"NOUN\"\n",
    "    elif d_tag.startswith(\"Q\"):\n",
    "         return \"NUM\"\n",
    "    elif d_tag.startswith(\"V\"):\n",
    "         return \"VERB\"\n",
    "    elif d_tag.startswith(\"G\"):\n",
    "         return \"PUNCT\"\n",
    "    elif d_tag.startswith(\"F\"):\n",
    "         return \"PRT\"\n",
    "    else:\n",
    "        return \"X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def new_prefix(sent):\n",
    "    for idx,(tag,word) in enumerate(sent):\n",
    "        \n",
    "        if((tag==\"PRT\" or tag==\"ADP\" or tag==\"CONJ\") and len(word)==1) and idx<len(sent)-2:\n",
    "            (t,w)=sent[idx+1]\n",
    "            if(w.startswith(\"ال\")and word=='ل'):\n",
    "                sent[idx+1]=(t,word+w[1:])\n",
    "                del sent[idx]\n",
    "            else:\n",
    "                sent[idx+1]=(t,word+w)\n",
    "                del sent[idx]\n",
    "             \n",
    "        if(tag==\"PRON\" and len(word)==1) and idx>1:\n",
    "            (t,w)=sent[idx-1]\n",
    "            if(w.endswith(\"ة\")):\n",
    "                sent[idx-1]=(t,w[:-1]+\"ت\"+word)\n",
    "                del sent[idx]\n",
    "            elif (w.endswith(\"ى\")):\n",
    "                sent[idx-1]=(t,w[:-1]+\"ي\"+word)\n",
    "                del sent[idx]\n",
    "            else: \n",
    "                sent[idx-1]=(t,w+word)\n",
    "                del sent[idx]\n",
    "              \n",
    "    return sent\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2996\n"
     ]
    }
   ],
   "source": [
    "list_sentences=[]\n",
    "for path in paths:\n",
    "    files = (file for file in os.listdir(os.path.join(os.path.realpath('..'),path)))\n",
    "    for file in files:\n",
    "        if os.path.isfile(os.path.join(os.path.realpath('..'),path, file)):\n",
    "            with open(os.path.join(os.path.realpath('..'),path)+file,\n",
    "            encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    splitcomma=re.split(',',line)\n",
    "                    if(len(splitcomma)>4):\n",
    "                        if(splitcomma[0].startswith('[#')):\n",
    "                            if(sent_no !=0 ):\n",
    "                                sentennce.sort(key=lambda tup: tup[1])\n",
    "                                sortedd=remove_index(sentennce)\n",
    "                                list_sentences.append(sortedd)\n",
    "                                sentennce =[]\n",
    "                            sent_no=splitcomma[0][2]\n",
    "                        else:\n",
    "                            for inn in splitcomma :\n",
    "                                if(inn.startswith('ord=')):\n",
    "                                    index=inn[4:]\n",
    "                            if(('PADT_LDC/data/UMH/syntax/') in path or ('PADT_LDC/data/XIN/syntax/' in path)):\n",
    "                                tag=map_tag(splitcomma[2][4:])\n",
    "                                sword=splitcomma[3]\n",
    "                            else:\n",
    "                                tag=map_tag(splitcomma[3])\n",
    "                                sword=splitcomma[4]\n",
    "                            word=deNoise(splitcomma[0][1:])\n",
    "                            tag_word=(tag,int(index),word)\n",
    "                            sentennce.append(tag_word)\n",
    "                   \n",
    "                   \n",
    "        \n",
    "        \n",
    "                            \n",
    "                   \n",
    "                 \n",
    "                    \n",
    "                   \n",
    "\n",
    "            \n",
    "sentennce.sort(key=lambda tup: tup[1])\n",
    "sortedd=remove_index(sentennce)\n",
    "list_sentences.append(sortedd)\n",
    "print(len(list_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(tagged):\n",
    "    for sent in tagged:\n",
    "        if(len(sent)==0):\n",
    "            tagged.remove(sent)\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tagged_sents():\n",
    "    tagged_sents=[]\n",
    "    tokB1=0\n",
    "\n",
    "    tokB=0\n",
    "    tokA=0\n",
    "    for sent in list_sentences:\n",
    "        tokB1=tokB1+len(sent)\n",
    "\n",
    "        fixed_sent=new_prefix(sent)\n",
    "        tokB=tokB+len(fixed_sent)\n",
    "        fixed_sent = [(t,w) for (t,w) in sent if (t!=\"X\" and t!=\"PUNCT\" and t!=\"NUM\")]\n",
    "        tokA=tokA+len(fixed_sent)\n",
    "        tagged_sents.append(fixed_sent)  \n",
    "    print(\"tokB\",tokB,\"tokA\",tokA,\"tokbb1\",tokB1)\n",
    "    return clean(tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokB 101431 tokA 76352 tokbb1 113733\n",
      "2797\n",
      "tokB 101239 tokA 76160 tokbb1 101431\n",
      "[('ADP', 'ول'), ('PRON', 'ه'), ('ADP', 'في'), ('NOUN', 'حقل'), ('NOUN', 'الترجمة'), ('NOUN', 'أعمال'), ('ADJ', 'عدة'), ('ADP', 'من'), ('NOUN', 'أبرز'), ('PRON', 'ها'), ('NOUN', 'رواية'), ('NOUN', 'الكاتب'), ('ADJ', 'الفرنسي'), ('VERB', 'وقيل'), ('CONJ', 'إن'), ('PRON', 'ها'), ('ADP', 'من'), ('NOUN', 'أفضل'), ('NOUN', 'الترجمات'), ('PRON', 'التي'), ('VERB', 'عرفت'), ('PRON', 'ها'), ('PRON', 'هذه'), ('NOUN', 'الرواية')]\n"
     ]
    }
   ],
   "source": [
    "print(len(tagged_sents()))\n",
    "print(tagged_sents()[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
