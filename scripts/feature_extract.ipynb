{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import PADTparsing as p\n",
    "import to_word2vec as wv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def features(sentence,index,history,hybrid):\n",
    "       \n",
    "        dic={\n",
    "            'word':sentence[index],\n",
    "            'word_length':len(sentence[index]),\n",
    "            'is_first':index==0,\n",
    "            'is_last':index==len(sentence)-1,\n",
    "            'prefix-1': '' if len(sentence[index])==0 else sentence[index][0],\n",
    "            'prefix-2':sentence[index][:2],\n",
    "            'prefix-3':sentence[index][:3],\n",
    "            'suffix-1':'' if len(sentence[index])==0 else sentence[index][-1],\n",
    "            'suffix-2':sentence[index][-2:],\n",
    "            'suffix-3':sentence[index][-3:],\n",
    "            'p_prev_word':''if index<=1 else sentence[index-2],\n",
    "            'prev_word':'' if index==0 else sentence[index-1],\n",
    "            'prev_tag':'' if index==0 else history[index-1],\n",
    "            'p_pev_tag':'' if index<=1 else history[index-2],                                  \n",
    "            'next_word':'' if index==len(sentence)-1 else sentence[index+1],\n",
    "            'n_next_word':'' if index>=len(sentence)-2 else sentence[index+2]\n",
    "        }\n",
    "        \n",
    "        if(hybrid):\n",
    "            \n",
    "            word=wv.word(sentence[index])\n",
    "\n",
    "            for i in range(300):\n",
    "                dic.update({'wordv'+str(i):word[i]})\n",
    "\n",
    "            if(index<=1):\n",
    "                for i in range(300):\n",
    "                    dic.update({'p_prev_wordv'+str(i):-1})\n",
    "            else :\n",
    "                p_prev_word=wv.word(sentence[index-2])\n",
    "                for i in range(300):\n",
    "                    dic.update({'p_prev_wordv'+str(i):p_prev_word[i]})\n",
    "\n",
    "            if(index==0):\n",
    "                for i in range(300):\n",
    "                    dic.update({'prev_wordv'+str(i):-1})\n",
    "            else :\n",
    "                prev_word= wv.word(sentence[index-1])\n",
    "                for i in range(300):\n",
    "                    dic.update({'prev_wordv'+str(i):prev_word[i]})\n",
    "\n",
    "            if(index==len(sentence)-1):\n",
    "                for i in range(300):\n",
    "                    dic.update({'next_wordv'+str(i):-1})\n",
    "            else :\n",
    "                next_word=wv.word(sentence[index+1])\n",
    "                for i in range(300):\n",
    "                    dic.update({'next_wordv'+str(i):next_word[i]})\n",
    "\n",
    "            if(index>=len(sentence)-2):\n",
    "                for i in range(300):\n",
    "                    dic.update({'n_next_wordv'+str(i):-1})\n",
    "            else :\n",
    "                n_next_word=wv.word(sentence[index+2])\n",
    "                for i in range(300):\n",
    "                    dic.update({'n_next_wordv'+str(i):n_next_word[i]})\n",
    "               \n",
    " \n",
    "       \n",
    "        \n",
    "        \n",
    "        return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero():\n",
    "    vec=[]\n",
    "    for i in range(300):\n",
    "         vec.append(-1)\n",
    "    return vec\n",
    "def neg():\n",
    "    vec=[]\n",
    "    for i in range(8):\n",
    "         vec.append(None)\n",
    "    return vec\n",
    "         \n",
    "def untag(sent):\n",
    "    return [w for (t,w) in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_features_set(tagged_sentences,hybrid):\n",
    "    global history\n",
    "    history=[]\n",
    "    features_set=[]\n",
    "    labels_set=[]\n",
    "    tagged_sentences=wv.out_vocab(tagged_sentences)\n",
    "    for sent in tagged_sentences:\n",
    "        for index in range(len(sent)):\n",
    "            features_set.append(features(untag(sent),index,labels_set,hybrid))\n",
    "            labels_set.append(sent[index][0])\n",
    "            history.append(sent[index][0])\n",
    "\n",
    "    return features_set,labels_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_tags(d_tag):\n",
    "        #print(\"fine\",d_tag)\n",
    "        if d_tag.startswith(\"PRON\"):\n",
    "              return 1;\n",
    "        elif d_tag.startswith(\"ADJ\"):\n",
    "             return 2;\n",
    "        elif d_tag.startswith(\"ADP\"):\n",
    "              return 3;\n",
    "        elif d_tag.startswith(\"ADV\"):\n",
    "              return 4;\n",
    "        elif d_tag.startswith(\"CONJ\"):\n",
    "              return 5;\n",
    "        elif d_tag.startswith(\"NOUN\"):\n",
    "             return 6;\n",
    "        elif d_tag.startswith(\"VERB\"):\n",
    "             return 7;\n",
    "        else: \n",
    "            \n",
    "             return 8;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(hybrid):\n",
    "    tagged_sentences = p.tagged_sents()\n",
    "    random.seed(5)\n",
    "\n",
    "    random.shuffle(tagged_sentences)\n",
    "    features_set,labels_set=prepare_features_set(tagged_sentences,hybrid)\n",
    "    features_set,f_names=victorize(features_set)\n",
    "    \n",
    "    split_factor=int(.75*features_set.shape[0])\n",
    "    featuers_train=features_set[:split_factor]\n",
    "    labels_train=labels_set[:split_factor]\n",
    "    feauters_test=features_set[split_factor:]\n",
    "    labels_test=labels_set[split_factor:]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return featuers_train,feauters_test,labels_train,labels_test,f_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def victorize(features):\n",
    "    vec = DictVectorizer()\n",
    "    featuers= vec.fit_transform(features) \n",
    "    return features,vec.feature_names_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def victorize(featuers_train,features_test,method,norm):\n",
    "    standard_scaler = StandardScaler(with_mean=False)\n",
    "    svd = TruncatedSVD(n_components=components,random_state=0)\n",
    "    enc = OneHotEncoder()\n",
    "    \n",
    "    if(method==\"svd\"):\n",
    "        train,test= standard_scaler.fit_transform(featuers_train),standard_scaler.fit_transform(featuers_test)\n",
    "        if(norm):\n",
    "            train,test = normalize(train, norm='max'),normalize(test, norm='max')\n",
    "        return train,test\n",
    "    if(method==\"enc\"):\n",
    "        train,test=enc.fit_transform(featuers_train),enc.fit_transform(featuers_test)\n",
    "        if(norm):\n",
    "            train,test = normalize(train, norm='max'),normalize(test, norm='max')\n",
    "        return train,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureSelection(featuers_train,feauters_test,labels_train):\n",
    "    support =SelectPercentile(chi2,percentile=90).fit(featuers_train,labels_train)\n",
    "    new_transformed_featuers_train=support.transform(featuers_train)\n",
    "    selected_features=support.get_support()\n",
    "    print(len(selected_features))\n",
    "    new_transformed_featuers_test=support.transform(feauters_test)\n",
    "    return new_transformed_featuers_train,new_transformed_featuers_test,selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visuializa_data():\n",
    "    featuers_train,feauters_test,labels_train,labels_test =split_data()\n",
    "    featuers_train,x_test,_=victorize(featuers_train,feauters_test)\n",
    "    #class_labels = 8\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels_train = label_encoder.fit_transform(labels_train)\n",
    "    y_test=label_encoder.fit_transform(labels_test)\n",
    "    svd = TruncatedSVD(n_components=2,algorithm=\"arpack\")\n",
    "    x_test_2d=svd.fit_transform(x_test)\n",
    "    #x_test_2d=x_test_2d.toarray()\n",
    "    # scatter plot the sample points among 5 classes\n",
    "    markers=('s', 'd', 'o', '^', 'v','p','P','*')\n",
    "    color_map = {0:'red', 1:'blue', 2:'lightgreen', 3:'purple', 4:'cyan',5:'yellow',6:'black',7:'magenta'}\n",
    "    plt.figure()\n",
    "    for idx, cl in enumerate(np.unique(y_test)):\n",
    "        plt.scatter(x=x_test_2d[y_test==cl,0], y=x_test_2d[y_test==cl,1], c=color_map[idx], marker=markers[idx], label=cl)\n",
    "    plt.xlabel('X in t-SVD')\n",
    "    plt.ylabel('Y in t-SVD')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('t-SVD visualization of test data')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
